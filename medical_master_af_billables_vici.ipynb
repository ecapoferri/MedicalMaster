{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers/Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import json\n",
    "import logging\n",
    "import traceback\n",
    "from os import environ as os_environ\n",
    "from sys import stdout\n",
    "from sqlalchemy.dialects.postgresql import BIGINT, INTEGER, ARRAY, TIMESTAMP, VARCHAR\n",
    "\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for verifying DB updates\n",
    "from db_engines import mms_db, rprt_db, wh_db as db\n",
    "\n",
    "tmstmp_fmt = r'%Y-%m-%d %H:%M:%S'\n",
    "query_date_fmt = r'%Y-%m-%d'\n",
    "file_name_date_fmt = r'%Y%m%d'\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as Df\n",
    "from pandas import Series as Ser\n",
    "\n",
    "today: str = datetime.now().strftime(query_date_fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fmt_date_strm = r'%y%m%d|%H%M'\n",
    "log_fmt_date_file = r'%Y-%m-%d %H:%M:%S'\n",
    "log_fmt_file = '%(asctime)s [%(name)s,%(funcName)s,%(module)s::%(levelname)s]>>%(message)s'\n",
    "log_fmt_strm = '\\x1b[32m%(asctime)s[%(name)s %(levelname)s]\\x1b[0m >> %(message)s'\n",
    "\n",
    "logger = logging.getLogger(os_environ['PRMDIA_MM_LOGNAME'])\n",
    "hdlr = logging.StreamHandler(stdout)\n",
    "hdlr.setFormatter(logging.Formatter(fmt=log_fmt_strm, datefmt=log_fmt_date_strm))\n",
    "# hdlr.setLevel(logging.DEBUG)\n",
    "logger.addHandler(hdlr)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yr_min, month_min, day_min = 2022, 10, 28  # yesterday or fri before mon\n",
    "# yr_lmt, month_lmt, day_lmt = 2022, 11, 1  # usually today\n",
    "\n",
    "lmt_date = datetime.now().date()\n",
    "\n",
    "# days before limit date (usually today)\n",
    "min_date: datetime = datetime(2022, 11, 28)\n",
    "\n",
    "day_range = 3\n",
    "\n",
    "# # comment out line below to use the explicit date\n",
    "# min_date: datetime = lmt_date - timedelta(days=day_range)\n",
    "max_date: datetime = lmt_date - timedelta(days=1)\n",
    "\n",
    "\n",
    "date_min: str\n",
    "date_lmt: str\n",
    "date_max: str\n",
    "date_min, date_lmt, date_max = (\n",
    "        d.strftime(query_date_fmt)\n",
    "        for d in (min_date, lmt_date, max_date)\n",
    "    )\n",
    "date_min_strrep, date_lmt_strrep, date_max_strrep = (\n",
    "        s.replace('-', '.')\n",
    "        for s in\n",
    "        (date_min, date_lmt, date_max)\n",
    "    )\n",
    "logger.debug(f\">={date_min_strrep}, < {date_lmt_strrep}, <= {date_max_strrep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output config\n",
    "client_lead_cols = json.loads(Path('client_lead_cols.json').read_text())\n",
    "\n",
    "type_map = {\n",
    "    'BIGINT': BIGINT,\n",
    "    'INT': INTEGER,\n",
    "    'VARCHAR[]': ARRAY(VARCHAR),\n",
    "    'TIMESTAMP': TIMESTAMP,\n",
    "}\n",
    "\n",
    "dtype = {\n",
    "    k: type_map[d['dtype']]\n",
    "    for k, d in client_lead_cols.items()\n",
    "    if d['dtype']\n",
    "}\n",
    "\n",
    "out_fn = f'RPRT.MEDMSTR-backup.{min_date.strftime(file_name_date_fmt)}_{max_date.strftime(file_name_date_fmt)}'\n",
    "out_pth = Path('sh') / 'local_repos' / 'RPRT.MEDMSTR-BACKUP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VICI CONFIGS\n",
    "base_url = 'http://10.1.10.20/vicidial/non_agent_api.php'\n",
    "static_params: dict[str, str|int|bool] = {\n",
    "    'user': 6666,\n",
    "    'pass': 'RedLakeSky3501',\n",
    "    'function': 'add_lead',\n",
    "    'custom_fields': 'Y',\n",
    "    'duplicate_check': 'DUPLIST30DAY',\n",
    "    'source': __name__\n",
    "}\n",
    "var_params: dict[str, str|int|bool] = {\n",
    "    'list_id': None,\n",
    "    'phone_number': None,\n",
    "    'STA': None\n",
    "}\n",
    "cmpgn_lists: dict = {\n",
    "    int(k): int(v) for k, v in\n",
    "    json.loads(\n",
    "        Path('campaign_lists.json')\n",
    "        .read_text()\n",
    "    ).items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for active connections, else raise exception and bail\n",
    "from db_engines import MySQL_OpErr, check_connection\n",
    "\n",
    "for d in db, rprt_db:\n",
    "    try:\n",
    "        check_connection(d)\n",
    "    except MySQL_OpErr:\n",
    "        raise Exception(f\"\\x1b[91mSEE BELOW/ABOVE\\x1b[0m\\n\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "del MySQL_OpErr, check_connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: Df\n",
    "with db.connect() as conn:\n",
    "    df = (\n",
    "        pd.read_sql_query(\n",
    "            f\"\"\"--sql\n",
    "                SELECT * FROM med_master_join\n",
    "                WHERE att_connected < '{date_lmt}'\n",
    "                AND att_connected >= '{date_min}'\n",
    "                ;\n",
    "            \"\"\".replace('--sql\\n', ''),\n",
    "            conn\n",
    "        )\n",
    "        .convert_dtypes()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign delivery dates and AF code to AF deliverables\n",
    "split_truth: Ser = df['af_client'].notna()\n",
    "\n",
    "\n",
    "df['DELIVERY_DATE'] = df['af_connected']\n",
    "\n",
    "df.loc[split_truth, ['DELIVERY_CODE']] = 'AF'\n",
    "\n",
    "df.loc[~split_truth, ['DELIVERY_DATE']] = pd.NA\n",
    "df.loc[~split_truth, ['DELIVERY_CODE']] = pd.NA\n",
    "\n",
    "df['PM_COMMENTS'] = pd.NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load af billables to table\n",
    "load = (\n",
    "    df.loc[\n",
    "        # has delivery code\n",
    "        df['DELIVERY_CODE'].notna(),\n",
    "        # select only needed columns\n",
    "        [d['orig'] for d in client_lead_cols.values()]\n",
    "    ]\n",
    "    .rename(columns={\n",
    "        d['orig']: k for k, d in\n",
    "        client_lead_cols.items()\n",
    "        if d['orig']\n",
    "    })\n",
    "    .astype({\n",
    "        k: d['astype'] for k, d in\n",
    "        client_lead_cols.items()\n",
    "        if d['astype']\n",
    "    })\n",
    ")\n",
    "with db.connect() as conn:\n",
    "    load.to_sql(\n",
    "        name='billables',\n",
    "        con=conn,\n",
    "        index=False,\n",
    "        if_exists='append',\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "    # delete any duplicates appended\n",
    "    conn.execute(\n",
    "        statement=\"\"\"--sql\n",
    "            DELETE FROM\n",
    "                billables a\n",
    "                    USING billables b\n",
    "            WHERE\n",
    "                a.id < b.id\n",
    "                AND a.toll_dialed = b.toll_dialed\n",
    "                AND a.client_callerid = b.client_callerid\n",
    "                AND a.lead_delivery_date = b.lead_delivery_date\n",
    "            ;\n",
    "        \"\"\".replace('--sql\\n', '')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load to vici\n",
    "# ***ED 105, Neuro 106, and Knee/WtLoss 107 ONLY UNTIL THE OTHER LISTS ARE READY***\n",
    "\n",
    "# where there is no delivery code\n",
    "for r in df.loc[~df['DELIVERY_CODE'].notna()].itertuples():\n",
    "    ph: int = r.att_callerid\n",
    "    # campaign id\n",
    "    cp: int = r.att_acct_af\n",
    "    list_id: int = cmpgn_lists[cp]\n",
    "\n",
    "    # caller state\n",
    "    st: str = r.att_state_agg[0]  # re.sub(r'[\\[\\]]', '', r.att_state_agg)\n",
    "\n",
    "    args = {\n",
    "        'list_id': list_id,\n",
    "        'phone_number': ph,\n",
    "        'STA': st\n",
    "    }\n",
    "    \n",
    "    # combine static args with variable args\n",
    "    if list_id != 108:\n",
    "        u = f\"{base_url}?{urlencode(static_params | args)}\"\n",
    "\n",
    "        logger.debug(f\"{u}\")\n",
    "\n",
    "        resp = requests.get(u)\n",
    "        logger.info(f\"ATT Orig. Ph.: {ph} Campaign ID: {cp} LIST ID: {list_id} ATT state: {st} >> {resp}\")\n",
    "        resp_log = f\"resp: {resp} >> {resp.text}\"\n",
    "        if re.findall('ERROR', resp.text):\n",
    "            logger.error(f\"\\t\" + resp_log.replace('\\n', '-|'))\n",
    "        else: logger.debug(resp_log)\n",
    "\n",
    "        # TODO: #3 #2 ADD COUNTER FOR GOOD RESPONSE, BAD RESPONSE, 200, 400, ETC\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('primedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4662a44a916367df8ac421768d70a5fecce726fb94060a48abc663edd1dcf4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
