{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers/Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import logging\n",
    "import traceback\n",
    "from os import environ as os_environ\n",
    "from sys import stdout\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for verifying DB updates\n",
    "from db_engines import rprt_db, wh_conn_str, wh_db as db\n",
    "\n",
    "tmstmp_fmt: str = r'%Y-%m-%d %H:%M:%S'\n",
    "query_date_fmt: str = r'%Y-%m-%d'\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as Df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER CONSTANTS\n",
    "today: str = datetime.now().strftime(query_date_fmt)\n",
    "repos_path = Path(os_environ['PRMDIA_EVAN_LOCAL_LAKEPATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TOLL-NUMBER MAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGGING SETUP\n",
    "log_fmt_date_strm = r'%y%m%d|%H%M'\n",
    "log_fmt_date_file = r'%Y-%m-%d %H:%M:%S'\n",
    "log_fmt_file =\\\n",
    "    '%(asctime)s [%(name)s,%(funcName)s,%(module)s::%(levelname)s]>>%(message)s'\n",
    "log_fmt_strm =\\\n",
    "    '\\x1b[32m%(asctime)s[%(name)s %(levelname)s]\\x1b[0m >> %(message)s'\n",
    "\n",
    "logger = logging.getLogger(os_environ['PRMDIA_MM_LOGNAME'])\n",
    "hdlr = logging.StreamHandler(stdout)\n",
    "hdlr.setFormatter(\n",
    "    logging.Formatter(\n",
    "        fmt=log_fmt_strm, datefmt=log_fmt_date_strm))\n",
    "# hdlr.setLevel(logging.DEBUG)\n",
    "logger.addHandler(hdlr)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PM PHONE NUMBERS\n",
    "pm_phone: Df\n",
    "with rprt_db.connect() as conn:\n",
    "    pm_phone = pd.read_sql_query(\n",
    "        sql=\"\"\"--sql\n",
    "            SELECT phone_dir FROM dim_phone\n",
    "        \"\"\".replace('--sql\\n', ''),\n",
    "        con=conn\n",
    "    )\n",
    "pm_phone: list[int] = list(pm_phone['phone_dir'])\n",
    "\n",
    "# create string for query\n",
    "# print(*[i for i in pm_phone], sep=', ')\n",
    "ph_not_in: str = ', '.join([str(i) for i in pm_phone])\n",
    "\n",
    "log_msg = ', '.join([str(i) for i in pm_phone])\n",
    "logger.debug(f\"PM phone nums excluded: \\n{log_msg}\")\n",
    "del log_msg\n",
    "\n",
    "with db.connect() as conn:\n",
    "    conn.execute(Path('master_join.pgsql').read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for active connections, else raise exception and bail\n",
    "from db_engines import MySQL_OpErr, check_connection\n",
    "\n",
    "for d in db, rprt_db:\n",
    "    try:\n",
    "        check_connection(d)\n",
    "    except MySQL_OpErr:\n",
    "        raise Exception(f\"\\x1b[91mSEE BELOW/ABOVE\\x1b[0m\\n\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "del MySQL_OpErr, check_connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LAKE VINTAGE CHECK\n",
    "from table_config import AF_CFGS, ATT_FILE_CFG\n",
    "rng = 5\n",
    "\n",
    "ansi = '\\x1b[{clr}m'\n",
    "good_ansi = ansi.format(clr='93')\n",
    "bad_ansi = ansi.format(clr='1;91')\n",
    "ansi_rst = '\\x1b[0m'\n",
    "rpo_chk_prstr = (\n",
    "    \"❇️{an}{nm}{anr}, source or top of glob for ({ds}) \"\n",
    "    + \"Repos Vintage: {an}{ts}{anr}\"\n",
    ")\n",
    "\n",
    "\n",
    "af_glob: str = AF_CFGS['src_label']\n",
    "att_glob: str = ATT_FILE_CFG['src_label']\n",
    "del AF_CFGS, ATT_FILE_CFG\n",
    "\n",
    "# get recent mtimes\n",
    "af_files: list[Path]\n",
    "att_files: list[Path]\n",
    "af_files, att_files = (\n",
    "    list(repos_path.rglob(glob))\n",
    "    for glob in (af_glob, att_glob)\n",
    ")\n",
    "\n",
    "for l, t in ((af_files, 'af_message_data'), (att_files, 'att_data')):\n",
    "    l.sort(reverse=True, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    for i in range(rng):\n",
    "        p = l[i]\n",
    "        t = datetime.fromtimestamp(p.stat().st_mtime)\n",
    "        ts = t.strftime(tmstmp_fmt)\n",
    "        nm = l[i].name\n",
    "\n",
    "        now, dlt = datetime.now(), timedelta(hours=(16))\n",
    "        clr = good_ansi if (now - t < dlt) else bad_ansi\n",
    "        del now, dlt\n",
    "\n",
    "        logger.info(rpo_chk_prstr.format(\n",
    "            an=clr, anr=ansi_rst, nm=nm, ds=t, ts=ts))\n",
    "\n",
    "        del clr, nm, ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL FROM REPOS\n",
    "from etl_att_repos import main as att\n",
    "from etl_af_repos import main as af\n",
    "from etl_client_key import main as client\n",
    "\n",
    "att_thr = Thread(target=att)\n",
    "af_thr = Thread(target=af)\n",
    "client_thr = Thread(target=client)\n",
    "threads = (\n",
    "    af_thr,\n",
    "    att_thr,\n",
    "    client_thr,\n",
    ")\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "del att_thr, af_thr, threads, att, af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view of master join\n",
    "xtra_sql_file = Path('master_join.pgsql').name\n",
    "psql_cmd: str = f\"psql --file={xtra_sql_file} {wh_conn_str}\"\n",
    "logger.info(f\"Re-instating master join view.\")\n",
    "!{psql_cmd} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('primedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4662a44a916367df8ac421768d70a5fecce726fb94060a48abc663edd1dcf4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
