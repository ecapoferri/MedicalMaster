{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers/Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from urllib.parse import urlencode\n",
    "import logging\n",
    "import traceback\n",
    "from os import environ as os_environ\n",
    "from sys import stdout\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for verifying DB updates\n",
    "from db_engines import rprt_db, wh_conn_str, wh_db as db\n",
    "\n",
    "tmstmp_fmt: str = r'%Y-%m-%d %H:%M:%S'\n",
    "query_date_fmt: str = r'%Y-%m-%d'\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as Df\n",
    "from pandas import Series as Ser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER CONSTANTS\n",
    "today: str = datetime.now().strftime(query_date_fmt)\n",
    "repos_path = Path(os_environ['PRMDIA_EVAN_LOCAL_LAKEPATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGGING SETUP\n",
    "log_fmt_date_strm = r'%y%m%d|%H%M'\n",
    "log_fmt_date_file = r'%Y-%m-%d %H:%M:%S'\n",
    "log_fmt_file = '%(asctime)s [%(name)s,%(funcName)s,%(module)s::%(levelname)s]>>%(message)s'\n",
    "log_fmt_strm = '\\x1b[32m%(asctime)s[%(name)s %(levelname)s]\\x1b[0m >> %(message)s'\n",
    "\n",
    "logger = logging.getLogger(os_environ['PRMDIA_MM_LOGNAME'])\n",
    "hdlr = logging.StreamHandler(stdout)\n",
    "hdlr.setFormatter(logging.Formatter(fmt=log_fmt_strm, datefmt=log_fmt_date_strm))\n",
    "# hdlr.setLevel(logging.DEBUG)\n",
    "logger.addHandler(hdlr)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PM PHONE NUMBERS\n",
    "pm_phone: Df\n",
    "with rprt_db.connect() as conn:\n",
    "    pm_phone = pd.read_sql_query(\n",
    "        sql=\"\"\"--sql\n",
    "            SELECT phone_dir FROM dim_phone\n",
    "        \"\"\".replace('--sql\\n', ''),\n",
    "        con=conn\n",
    "    )\n",
    "pm_phone: list[int] = list(pm_phone['phone_dir'])\n",
    "\n",
    "# create string for query\n",
    "# print(*[i for i in pm_phone], sep=', ')\n",
    "ph_not_in: str = ', '.join([str(i) for i in pm_phone])\n",
    "\n",
    "log_msg = ', '.join([str(i) for i in pm_phone])\n",
    "logger.debug(f\"PM phone nums excluded: \\n{log_msg}\")\n",
    "del log_msg\n",
    "\n",
    "with db.connect() as conn:\n",
    "    conn.execute(Path('master_join.pgsql').read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> Checking Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr) -->\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> \t('Hello There',)\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> --> \u001b[32mEngine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr) \u001b[1m✔️\u001b[0m\n",
      "\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> Checking Engine(postgresql://pmrprt:***@127.0.0.1:55432/rprt) -->\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> \t('Hello There',)\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> --> \u001b[32mEngine(postgresql://pmrprt:***@127.0.0.1:55432/rprt) \u001b[1m✔️\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for active connections, else raise exception and bail\n",
    "from db_engines import MySQL_OpErr, check_connection\n",
    "\n",
    "for d in db, rprt_db:\n",
    "    try:\n",
    "        check_connection(d)\n",
    "    except MySQL_OpErr:\n",
    "        raise Exception(f\"\\x1b[91mSEE BELOW/ABOVE\\x1b[0m\\n\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "del MySQL_OpErr, check_connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93mRPRT.AF-msg_data_6933.2022-11-30.xls\u001b[0m, source or top of glob for (2022-12-01 08:21:14) Repos Vintage: \u001b[93m2022-12-01 08:21:14\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93mRPRT.AF-msg_data_9816.2022-11-30.xls\u001b[0m, source or top of glob for (2022-12-01 08:20:53) Repos Vintage: \u001b[93m2022-12-01 08:20:53\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93mRPRT.AF-msg_data_11888.2022-11-30.xls\u001b[0m, source or top of glob for (2022-12-01 08:20:52) Repos Vintage: \u001b[93m2022-12-01 08:20:52\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93mRPRT.AF-msg_data_7930.2022-11-30.xls\u001b[0m, source or top of glob for (2022-12-01 08:18:19) Repos Vintage: \u001b[93m2022-12-01 08:18:19\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[1;91mRPRT.AF-msg_data_11888.2022-11-29.xls\u001b[0m, source or top of glob for (2022-11-30 08:21:12) Repos Vintage: \u001b[1;91m2022-11-30 08:21:12\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93m2022-12-01T08_16_30+00_00DAILY DEBT - ANSWER FIRST 11888 - GUARDIAN FINAL EXPENSE.tab.gz\u001b[0m, source or top of glob for (2022-12-01 02:16:49) Repos Vintage: \u001b[93m2022-12-01 02:16:49\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93m2022-12-01T07_39_48+00_00DAILY DEBT - ANSWER FIRST 9816 - KNEE - WEIGHT LOSS.tab.gz\u001b[0m, source or top of glob for (2022-12-01 01:40:06) Repos Vintage: \u001b[93m2022-12-01 01:40:06\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93m2022-12-01T07_39_20+00_00DAILY DEBT - ANSWER FIRST 7930 - NEUROPATHY - ACTIVE LIFE.tab.gz\u001b[0m, source or top of glob for (2022-12-01 01:39:39) Repos Vintage: \u001b[93m2022-12-01 01:39:39\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93m2022-12-01T07_39_05+00_00DAILY DEBT - ANSWER FIRST 6933 - ED.tab.gz\u001b[0m, source or top of glob for (2022-12-01 01:39:23) Repos Vintage: \u001b[93m2022-12-01 01:39:23\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> ❇️\u001b[93m2022-12-01T05_57_20+00_00DAILY DEBT - ANSWER FIRST 9816 - KNEE - WEIGHT LOSS.tab.gz\u001b[0m, source or top of glob for (2022-11-30 23:57:38) Repos Vintage: \u001b[93m2022-11-30 23:57:38\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# DATA LAKE VINTAGE CHECK\n",
    "from table_config import af_cfgs, att_file_cfg\n",
    "rng = 5\n",
    "\n",
    "ansi = '\\x1b[{clr}m'\n",
    "good_ansi = ansi.format(clr='93')\n",
    "bad_ansi = ansi.format(clr='1;91')\n",
    "ansi_rst = '\\x1b[0m'\n",
    "rpo_chk_prstr = \"❇️{an}{nm}{anr}, source or top of glob for ({ds}) Repos Vintage: {an}{ts}{anr}\"\n",
    "\n",
    "\n",
    "af_glob: str = af_cfgs['src_label'].replace('||', '*')\n",
    "att_glob: str = att_file_cfg['src_label'].split('||')[1]\n",
    "del af_cfgs, att_file_cfg\n",
    "\n",
    "# get recent mtimes\n",
    "af_files: list[Path]\n",
    "att_files: list[Path]\n",
    "af_files, att_files = (\n",
    "    list(repos_path.rglob(glob))\n",
    "    for glob in (af_glob, att_glob)\n",
    ")\n",
    "\n",
    "for l, t in ((af_files, 'af_message_data'), (att_files, 'att_data')):\n",
    "    l.sort(reverse=True, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    for i in range(rng):\n",
    "        p = l[i]\n",
    "        t = datetime.fromtimestamp(p.stat().st_mtime)\n",
    "        ts = t.strftime(tmstmp_fmt)\n",
    "        nm = l[i].name\n",
    "\n",
    "        now, dlt = datetime.now(), timedelta(hours=(16))\n",
    "        clr = good_ansi if (now - t < dlt) else bad_ansi\n",
    "        del now, dlt\n",
    "\n",
    "        logger.info(rpo_chk_prstr.format(\n",
    "            an=clr, anr=ansi_rst, nm=nm, ds=t, ts=ts))\n",
    "\n",
    "        del clr, nm, ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> \u001b[36;1mSuccessfully loaded d_practice to Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr)\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> \u001b[36;1mSuccessfully loaded att_data to Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr)\u001b[0m\n",
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> \u001b[36;1mSuccessfully loaded af_message_data to Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ETL FROM REPOS\n",
    "from etl_att_repos import main as att\n",
    "from etl_af_repos import main as af\n",
    "from etl_client_key import main as client\n",
    "\n",
    "att_thr = Thread(target=att)\n",
    "af_thr = Thread(target=af)\n",
    "client_thr = Thread(target=client)\n",
    "threads = (\n",
    "        af_thr,\n",
    "        att_thr,\n",
    "        client_thr\n",
    "    )\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "del att_thr, af_thr, threads, att, af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m221201|1059[med_mstr INFO]\u001b[0m >> Re-instating master join view.\n",
      "CREATE VIEW\n"
     ]
    }
   ],
   "source": [
    "# create view of master join\n",
    "xtra_sql_file = Path('master_join.pgsql').name\n",
    "psql_cmd: str = f\"psql --file={xtra_sql_file} {wh_conn_str}\"\n",
    "logger.info(f\"Re-instating master join view.\")\n",
    "!{psql_cmd} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('primedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4662a44a916367df8ac421768d70a5fecce726fb94060a48abc663edd1dcf4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
