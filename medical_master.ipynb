{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers/Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m2022-11-01 15:34:46\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import dotenv\n",
    "from os import system\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "from db_engines import wh_db as db, rprt_db, mms_db\n",
    "# for verifying DB updates\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "tmstmp_fmt: str = r'%Y-%m-%d %H:%M:%S'\n",
    "query_date_fmt: str = r'%Y-%m-%d'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series as Ser, DataFrame as Df\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def stamp() -> str:\n",
    "    # print(f\"\\x1b[95m{datetime.now().strftime(tmstmp_fmt)}\\x1b[0m\")\n",
    "    return f\"\\x1b[95m{datetime.now().strftime(tmstmp_fmt)}\\x1b[0m\"\n",
    "    # return f\"\\x1b[95m{datetime.now().date().strftime(r'%Y.%m.%d')}\\x1b[0m\"\n",
    "\n",
    "today: str = datetime.now().strftime(query_date_fmt)\n",
    "\n",
    "\n",
    "print(stamp())\n",
    "skip_hs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yr_min, month_min, day_min = 2022, 10, 28  # yesterday or fri before mon\n",
    "# yr_lmt, month_lmt, day_lmt = 2022, 11, 1  # usually today\n",
    "\n",
    "# min_date: datetime\n",
    "# lmt_date: datetime\n",
    "# min_date, lmt_date = (\n",
    "#         datetime(year=y, month=m, day=d).date()\n",
    "#         for y, m, d in\n",
    "#         (\n",
    "#             (yr_min, month_min, day_min),\n",
    "#             (yr_lmt, month_lmt, day_lmt)\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# yr_lmt, month_lmt, day_lmt = 2022, 11, 1  # usually today\n",
    "# lmt_date: datetime = datetime(year=yr_lmt, month=month_lmt, day=date_lmt)\n",
    "lmt_date = datetime.now().date()\n",
    "\n",
    "day_range = 4\n",
    "min_date: datetime = lmt_date - timedelta(days=day_range)\n",
    "max_date: datetime = lmt_date - timedelta(days=1)\n",
    "\n",
    "\n",
    "date_min: str\n",
    "date_lmt: str\n",
    "date_max: str\n",
    "date_min, date_lmt, date_max = (\n",
    "        d.strftime(query_date_fmt)\n",
    "        for d in (min_date, lmt_date, max_date)\n",
    "    )\n",
    "date_min_strrep, date_lmt_strrep, date_max_strrep = (\n",
    "        s.replace('-', '.')\n",
    "        for s in\n",
    "        (date_min, date_lmt, date_max)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SCRIPT CHECKING MTIMES FOR SUBSCRIPTION FILES TO VERIFY THEY'RE FLOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PM PHONE NUMBERS\n",
    "pm_phone: Df\n",
    "with rprt_db.connect() as conn:\n",
    "    pm_phone = pd.read_sql_query(\n",
    "        sql=\"\"\"--sql\n",
    "            SELECT phone_dir FROM dim_phone\n",
    "        \"\"\".replace('--sql\\n', ''),\n",
    "        con=conn\n",
    "    )\n",
    "pm_phone: list[int] = list(pm_phone['phone_dir'])\n",
    "\n",
    "# create string for query\n",
    "# print(*[i for i in pm_phone], sep=', ')\n",
    "ph_not_in: str = ', '.join([str(i) for i in pm_phone])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 269 entries, 0 to 268\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   tollf_num         269 non-null    string        \n",
      " 1   rtn_new           244 non-null    string        \n",
      " 2   affixed           235 non-null    boolean       \n",
      " 3   campaign          155 non-null    string        \n",
      " 4   client            155 non-null    string        \n",
      " 5   endpoint          116 non-null    string        \n",
      " 6   rtn_line          267 non-null    string        \n",
      " 7   btn_line          267 non-null    string        \n",
      " 8   line_active_date  267 non-null    datetime64[ns]\n",
      "dtypes: boolean(1), datetime64[ns](1), string(7)\n",
      "memory usage: 17.5 KB\n"
     ]
    }
   ],
   "source": [
    "# LOAD TOLL MASTER\n",
    "tolls_astype: dict[str, str] = {\n",
    "        'tollf_num': 'string',\n",
    "        'rtn_new': 'string',\n",
    "        'affixed': 'boolean',\n",
    "        'campaign': 'string',\n",
    "        'client': 'string',\n",
    "        'endpoint': 'string',\n",
    "        'rtn_line': 'string',\n",
    "        'btn_line': 'string',\n",
    "        'line_active_date': 'datetime64[ns]'\n",
    "    }\n",
    "\n",
    "tolls: Df = (\n",
    "    pd.read_csv('toll_list.csv', encoding='utf-8')\n",
    "    .astype('string')\n",
    ")\n",
    "# fix phone numbers\n",
    "tolls[['tollf_num', 'rtn_new', 'endpoint', 'rtn_line', 'btn_line']] = \\\n",
    "    (\n",
    "        tolls[['tollf_num', 'rtn_new', 'endpoint', 'rtn_line', 'btn_line']]\n",
    "        .replace(r'[^\\d]', '', regex=True)\n",
    ")\n",
    "tolls['affixed'] = \\\n",
    "    tolls['affixed'].map(\n",
    "        {'Yes': True, 'No': False},\n",
    "        na_action='ignore'\n",
    "    )\n",
    "# fill empty 'client' field\n",
    "tolls['client'] = \\\n",
    "    tolls['client'].fillna(tolls['campaign'])\n",
    "tolls['line_active_date'] = \\\n",
    "    pd.to_datetime(\n",
    "        tolls['line_active_date']\n",
    "        .str.replace('.0', '', regex=False)\n",
    "    )\n",
    "\n",
    "tolls = tolls.astype(tolls_astype)\n",
    "tolls.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m2022-11-01 15:35:21\u001b[0m\n",
      "Checking Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr) -->\n",
      "\t('Hello There',)\n",
      "--> \u001b[32mEngine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr) \u001b[1m✔️\u001b[0m\n",
      "\n",
      "Checking Engine(postgresql://pmrprt:***@127.0.0.1:55432/rprt) -->\n",
      "\t('Hello There',)\n",
      "--> \u001b[32mEngine(postgresql://pmrprt:***@127.0.0.1:55432/rprt) \u001b[1m✔️\u001b[0m\n",
      "\n",
      "Checking Engine(mysql+mysqldb://evan:***@127.0.0.1:3306/dmp) -->\n",
      "\t('Hello There',)\n",
      "--> \u001b[32mEngine(mysql+mysqldb://evan:***@127.0.0.1:3306/dmp) \u001b[1m✔️\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for active connections, else raise exception and bail\n",
    "from db_engines import MySQL_OpErr, check_connection\n",
    "print(stamp())\n",
    "\n",
    "for d in db, rprt_db, mms_db:\n",
    "    try:\n",
    "        check_connection(d)\n",
    "    except MySQL_OpErr:\n",
    "        raise Exception(f\"\\x1b[91mSEE BELOW/ABOVE\\x1b[0m\\n\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "del MySQL_OpErr, check_connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Tbls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Tbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1mSuccessfully loaded att_data to Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr)\u001b[0m\n",
      "\u001b[36;1mSuccessfully loaded af_message_data to Engine(postgresql://pmrprt:***@127.0.0.1:55432/medmstr)\n"
     ]
    }
   ],
   "source": [
    "# att from mms MySQL\n",
    "%run ./etl_mms_att.py\n",
    "%run ./etl_af.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_join_sql: str = f\"\"\"--sql\n",
    "WITH\n",
    "    p AS (\n",
    "        SELECT *\n",
    "        FROM att_data\n",
    "        WHERE\n",
    "            connected < '{date_lmt}'\n",
    "            AND\n",
    "            connected >= '{date_min}'\n",
    "    ),\n",
    "    m AS (\n",
    "        SELECT *\n",
    "        FROM af_message_data\n",
    "        WHERE\n",
    "            connected < '{date_lmt}'\n",
    "            AND\n",
    "            connected >= '{date_min}'\n",
    "    )\n",
    "\"\"\".replace('--sql', '') + \"\"\"--sql\n",
    "SELECT\n",
    "    -- COUNT(p.created) AS mms_createds,\n",
    "    -- these 6 are the identifying fields, the rest are aggregated\n",
    "   --\n",
    "   p.number_orig AS att_callerid,\n",
    "   m.callerid AS af_callerid,\n",
    "   p.number_dial AS toll,\n",
    "   p.number_term AS att_fwd,\n",
    "   --\n",
    "    -- this could be useful, some ATT records have a zero duration,\n",
    "    -- summing this agg may be useful for filtering those out\n",
    "    -- count att connection timestamps as calls, shouldn't have nulls\n",
    "    COUNT(p.connected) AS att_connections,\n",
    "    array_agg(p.duration) AS att_durations,\n",
    "    array_agg(DISTINCT(p.id)) AS att_ids,\n",
    "    -- att joined calls will have an AF connection ts,\n",
    "    -- but counts of nulls will resolve to zero,\n",
    "    -- this will resolve zero counts to null\n",
    "   --\n",
    "   m.acct AS af_acct,\n",
    "   --\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.recording_id)), NULL), '{}')\n",
    "        af_ids,\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.practice_id)), NULL), '{}')\n",
    "        practice_id,\n",
    "    NULLIF(COUNT(m.connected), 0)\n",
    "        af_connections,\n",
    "    -- COALESCES TO TRUE IF ANY WERE TRUE\n",
    "    CASE WHEN NULLIF(COUNT(m.connected), 0) IS NOT NULL\n",
    "        THEN ARRAY_REPLACE(array_agg(m.call_for_ad), NULL, FALSE) @> ARRAY[TRUE]\n",
    "        ELSE NULL\n",
    "        END\n",
    "    call_for_ad,\n",
    "    -- \n",
    "    -- the rest are just lists of existing results\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.besttime)), NULL), '{}')\n",
    "        af_msg_besttimes,\n",
    "    NULLIF(array_remove(array_agg(m.sent_emails_to), NULL), '{}')\n",
    "        af_msg_emailed,\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.caller_name)), NULL), '{}')\n",
    "        af_msg_caller_name,\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.phone)), NULL), '{}')\n",
    "        af_msg_given_phones,\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.email)), NULL), '{}')\n",
    "        af_msg_given_emails,\n",
    "    NULLIF(array_remove(array_agg(DISTINCT(m.addr_state)), NULL), '{}')\n",
    "        af_msg_given_addr_state,\n",
    "    NULLIF(array_remove(array_agg(m.reference), NULL), '{}')\n",
    "        af_msg_bodies,\n",
    "    NULLIF(array_remove(array_agg(m.dispo), NULL), '{}')\n",
    "        af_dispos,\n",
    "    NULLIF(array_remove(array_agg(m.history), NULL), '{}')\n",
    "        af_hists\n",
    "\n",
    "\n",
    "FROM\n",
    "    p FULL OUTER JOIN m\n",
    "    ON m.callerid = p.number_orig\n",
    "    AND m. = p.number_dial\n",
    "\"\"\".replace('--sql', '') + f\"\"\"--sql\n",
    "WHERE p.number_orig NOT IN ({ph_not_in})\n",
    "GROUP BY\n",
    "    att_callerid,\n",
    "    af_callerid,\n",
    "    toll,\n",
    "    af_acct,\n",
    "    att_fwd\n",
    ";\n",
    "\"\"\".replace('--sql', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db.connect() as conn:\n",
    "    mj_df = pd.read_sql_query(master_join_sql, conn).convert_dtypes()\n",
    "mj_df.to_csv('medical_master.master_join.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "billables: Df = (\n",
    "    mj_df.copy()\n",
    "    .loc[mj_df['af_dispos'].notna()]\n",
    ")\n",
    "\n",
    "billables.af_hists = (\n",
    "    billables.af_hists\n",
    "    .apply(\n",
    "        lambda x:\n",
    "            '\\n'.join([str(s).replace('\\r', '') for s in x])\n",
    "            if x else x\n",
    "        )\n",
    ")\n",
    "billables.af_dispos = (\n",
    "    billables.af_dispos\n",
    "    .apply(\n",
    "        lambda x:\n",
    "            '\\n'.join([str(s).replace('\\r', '') for s in x])\n",
    "            if x else x\n",
    "        )\n",
    ")\n",
    "billables.toll = billables.toll.astype('string').str.zfill(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols: list[str] = [\n",
    "    'att_callerid',\n",
    "    'af_callerid',\n",
    "    'toll',\n",
    "    'att_fwd',\n",
    "    'af_acct',\n",
    "    'af_ids',\n",
    "    'practice_id',\n",
    "    'af_connections',\n",
    "    'call_for_ad',\n",
    "    'af_msg_besttimes',\n",
    "    'af_msg_emailed',\n",
    "    'af_msg_caller_name',\n",
    "    'af_msg_given_phones',\n",
    "    'af_msg_given_emails',\n",
    "]\n",
    "\n",
    "for_text: Df = (\n",
    "    mj_df.copy()\n",
    "    .loc[\n",
    "        mj_df['af_dispos'].isna(),\n",
    "        text_cols\n",
    "    ]\n",
    "    \n",
    ")\n",
    "for_text['phone_number'] = for_text['att_callerid'].fillna(for_text['af_callerid'])\n",
    "\n",
    "text_cols: list[str] = [\n",
    "    'phone_number',\n",
    "    'toll',\n",
    "    'att_fwd',\n",
    "    'af_acct',\n",
    "    'af_ids',\n",
    "    'practice_id',\n",
    "    'af_connections',\n",
    "    'call_for_ad',\n",
    "    'af_msg_besttimes',\n",
    "    'af_msg_emailed',\n",
    "    'af_msg_caller_name',\n",
    "    'af_msg_given_phones',\n",
    "    'af_msg_given_emails',\n",
    "]\n",
    "for_text = for_text[text_cols]\n",
    "for_text.toll = for_text.toll.astype('string').str.zfill(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_text, billables = (\n",
    "#     pd.merge(\n",
    "#         d.copy(),\n",
    "#         tolls[['campaign', 'client', 'tollf_num']],\n",
    "#         how='left', left_on='toll', right_on='tollf_num'\n",
    "#     )\n",
    "#     .drop(columns='tollf_num')\n",
    "\n",
    "#     for d in (for_text, billables)\n",
    "# )\n",
    "\n",
    "# # add date range column\n",
    "\n",
    "# for_text['date_range'] = billables['date_range'] = f\"{date_min_strrep}-{date_max_strrep}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "billables.to_csv(f'billables.csv', index=False, encoding='utf-8')\n",
    "for_text.to_csv(f'for_text.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('primedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4662a44a916367df8ac421768d70a5fecce726fb94060a48abc663edd1dcf4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
